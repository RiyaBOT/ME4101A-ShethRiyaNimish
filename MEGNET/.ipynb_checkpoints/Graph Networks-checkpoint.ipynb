{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materials Graph Networks (MEGNET)\n",
    "### Sheth Riya Nimish\n",
    "### A0176880R\n",
    "e0235287@u.nus.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source\n",
    "\n",
    "#### Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals\n",
    "\n",
    "#### Chi Chen, Weike Ye, Yunxing Zuo, Chen Zheng, and Shyue Ping Ong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code here is to execute the materials graph network. The code here has been written by me from scratch while the model used is a published model. \n",
    "\n",
    "The model was published in the following github repository: https://github.com/materialsvirtuallab/megnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Contents\n",
    "\n",
    "* [Importing the Required Libraries](#import)\n",
    "* [Creating a MEGNET Model](#create)\n",
    "* [Reading the Required Data From a File](#read)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Required Libraries<a class=\"anchor\" id=\"import\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen import Structure, Lattice\n",
    "from megnet.models import MEGNetModel\n",
    "from megnet.data.crystal import CrystalGraph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Required Libraries<a class=\"anchor\" id=\"create\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeat_bond = 10\n",
    "r_cutoff = 5\n",
    "gaussian_centers = np.linspace(0, r_cutoff + 1, nfeat_bond)\n",
    "gaussian_width = 0.5\n",
    "graph_converter = CrystalGraph(cutoff=r_cutoff)\n",
    "model = MEGNetModel(graph_converter=graph_converter, centers=gaussian_centers, width=gaussian_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Required Data from a File<a class=\"anchor\" id=\"read\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter File Name:k\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ea1278024c40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilenmae\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter File Name:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Material'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpropertylist\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Property'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "filename= input(\"Enter File Name:\")\n",
    "tp= pd.read_csv(filename)\n",
    "filenames= tp['Material'].values.tolist()\n",
    "propertylist= tp['Property'].values.tolist()\n",
    "actual= tp['Actual'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure=[]\n",
    "for i in range (1, len(filenames)):\n",
    "    temp= \"cifcopy/\" +filenames[i]+ \".cif\"\n",
    "    structure.append(Structure.from_file(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(structure, propertylist, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy():\n",
    "    choice= [0, 1]\n",
    "    count=0\n",
    "    for i in range (0, len(structure)):\n",
    "        temp= model.predict_structure(structure[i])\n",
    "        t= temp[0]\n",
    "        result= random.choices(choice, weights= (1-t, t), k=1)\n",
    "        if result[0] == propertylist[i]:\n",
    "            count= count+1\n",
    "            \n",
    "    accuracy= count/len(structure)\n",
    "    print(\"The accuracy is\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.5123995808592385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5123995808592385"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 25s 1s/step - loss: 15.1429\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 14.5213\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 22s 953ms/step - loss: 14.4431\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 26s 1s/step - loss: 14.2461\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.3503\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 14.7767\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.1856\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.0517\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.1424\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.1434\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 14.0617\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 13.9007\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.0338\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 27s 1s/step - loss: 13.9452\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 30s 1s/step - loss: 13.9152\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 25s 1s/step - loss: 13.9829\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 26s 1s/step - loss: 14.1215\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 23s 999ms/step - loss: 14.0223\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 27s 1s/step - loss: 14.4801\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 29s 1s/step - loss: 13.7965\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 29s 1s/step - loss: 13.7759\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 25s 1s/step - loss: 13.7079\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 28s 1s/step - loss: 13.7807\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 27s 1s/step - loss: 13.9569\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 25s 1s/step - loss: 13.7991\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 13.8489\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.2384\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 13.9000\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.1153\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 23s 994ms/step - loss: 13.7881\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 20s 882ms/step - loss: 14.4373\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 21s 914ms/step - loss: 13.7505\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.1262\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 23s 986ms/step - loss: 13.9195\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 14.6765\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 22s 963ms/step - loss: 13.7724\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 14.3494\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 13.8356\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 22s 949ms/step - loss: 13.7280\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 13.7591\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 22s 976ms/step - loss: 14.1030\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 13.8126\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 13.7890\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 20s 890ms/step - loss: 14.1682\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 31s 1s/step - loss: 13.8804\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 28s 1s/step - loss: 13.8664\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 28s 1s/step - loss: 13.7070\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 26s 1s/step - loss: 13.8209\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 13.8596\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 13.6906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<megnet.models.megnet.MEGNetModel at 0x14ce50160>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(structure, actual, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building my own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Structure Summary\n",
       "Lattice\n",
       "    abc : 3.21119894 3.21143469 20.005301\n",
       " angles : 90.0 90.0 119.99758194\n",
       " volume : 178.6703999058667\n",
       "      A : 3.21119894 0.0 1.9662922516481867e-16\n",
       "      B : -1.6055999689589022 2.7812517879211454 1.966436606889636e-16\n",
       "      C : 0.0 0.0 20.005301\n",
       "PeriodicSite: Ga (-0.0000, 1.8542, 10.0006) [0.3333, 0.6667, 0.4999]\n",
       "PeriodicSite: N (-0.0000, 0.0002, 10.0047) [0.0000, 0.0001, 0.5001]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Structure Summary\n",
       "Lattice\n",
       "    abc : 2.67149725 2.66230307 22.343883\n",
       " angles : 90.0 90.0 90.0\n",
       " volume : 158.91718847411965\n",
       "      A : 2.67149725 0.0 1.6358202780717281e-16\n",
       "      B : -1.630190466517836e-16 2.66230307 1.630190466517836e-16\n",
       "      C : 0.0 0.0 22.343883\n",
       "PeriodicSite: Ga (-0.0000, 1.9967, 12.4884) [0.0000, 0.7500, 0.5589]\n",
       "PeriodicSite: Ga (-0.0000, 0.6656, 9.8554) [0.0000, 0.2500, 0.4411]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from megnet.layers import MEGNetLayer, Set2Set\n",
    "\n",
    "n_atom_feature= 20\n",
    "n_bond_feature = 10\n",
    "n_global_feature = 2\n",
    "\n",
    "# Define model inputs\n",
    "int32 = 'int32'\n",
    "x1 = Input(shape=(None, n_atom_feature)) # atom feature placeholder\n",
    "x2 = Input(shape=(None, n_bond_feature)) # bond feature placeholder\n",
    "x3 = Input(shape=(None, n_global_feature)) # global feature placeholder\n",
    "x4 = Input(shape=(None,), dtype=int32) # bond index1 placeholder\n",
    "x5 = Input(shape=(None,), dtype=int32) # bond index2 placeholder\n",
    "x6 = Input(shape=(None,), dtype=int32) # atom_ind placeholder\n",
    "x7 = Input(shape=(None,), dtype=int32) # bond_ind placeholder\n",
    "xs = [x1, x2, x3, x4, x5, x6, x7]\n",
    "\n",
    "\n",
    "# Pass the inputs to the MEGNetLayer layer\n",
    "# Here the list are the hidden units + the output unit, \n",
    "# you can have others like [n1] or [n1, n2, n3 ...] if you want. \n",
    "out = MEGNetLayer([32, 16], [32, 16], [32, 16], pool_method='mean', activation='relu')(xs)\n",
    "\n",
    "# the output is a tuple of new graphs V, E and u\n",
    "# Since u is a per-structure quantity, \n",
    "# we can directly use it to predict per-structure property\n",
    "out = Dense(1)(out[2])\n",
    "\n",
    "# Set up the model and compile it!\n",
    "model = Model(inputs=xs, outputs=out)\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'pymatgen.core.structure.Structure'>, (<class 'list'> containing values of types {\"<class 'int'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b3de7df0eff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    966\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    969\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'pymatgen.core.structure.Structure'>, (<class 'list'> containing values of types {\"<class 'int'>\"})"
     ]
    }
   ],
   "source": [
    "model.fit(structure[0], [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficulties:\n",
    "Further improvment\n",
    "Regression\n",
    "Error in making model\n",
    "Third paper\n",
    "Can other algoirthms like LTSM, CNN work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
