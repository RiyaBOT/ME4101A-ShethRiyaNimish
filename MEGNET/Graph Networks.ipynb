{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materials Graph Networks (MEGNET)\n",
    "### Sheth Riya Nimish\n",
    "### A0176880R\n",
    "e0235287@u.nus.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source\n",
    "\n",
    "#### Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals\n",
    " Chi Chen, Weike Ye, Yunxing Zuo, Chen Zheng, and Shyue Ping Ong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code here is to execute the materials graph network. The code here has been written by me from scratch while the model used is a published model. \n",
    "\n",
    "The model was published in the following github repository: https://github.com/materialsvirtuallab/megnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Contents\n",
    "\n",
    "* [Importing the Required Libraries](#import)\n",
    "* [Creating a MEGNET Model](#create)\n",
    "* [Reading the Required Data From a File](#read)\n",
    "* [Extracting the Structures from the CIF files](#extract)\n",
    "* [Training the Model](#train)\n",
    "* [Calculating the Accuracy](#acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MatErials Graph Network (MEGNet) is an implementation of DeepMind's graph networks[1] for universal machine learning in materials science. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Required Libraries<a class=\"anchor\" id=\"import\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen import Structure, Lattice\n",
    "from megnet.models import MEGNetModel\n",
    "from megnet.data.crystal import CrystalGraph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a MEGNET Model <a class=\"anchor\" id=\"create\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of the parameters which can be optimised and fine tuned\n",
    "nfeat_bond = 10 \n",
    "r_cutoff = 5\n",
    "gaussian_centers = np.linspace(0, r_cutoff + 1, nfeat_bond)\n",
    "gaussian_width = 0.5\n",
    "graph_converter = CrystalGraph(cutoff=r_cutoff)\n",
    "model = MEGNetModel(graph_converter=graph_converter, centers=gaussian_centers, width=gaussian_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Required Data from a File<a class=\"anchor\" id=\"read\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter File Name:datamegnet.csv\n"
     ]
    }
   ],
   "source": [
    "filename= input(\"Enter File Name:\")\n",
    "tp= pd.read_csv(filename)\n",
    "filenames= tp['Material'].values.tolist()\n",
    "propertylist= tp['Property'].values.tolist()\n",
    "actual= tp['Actual'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Structures from the CIF files <a class=\"anchor\" id=\"extract\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riyasheth/.local/lib/python3.8/site-packages/pymatgen/io/cif.py:1123: UserWarning: Issues encountered while parsing CIF: Some fractional co-ordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  warnings.warn(\"Issues encountered while parsing CIF: %s\" % \"\\n\".join(self.warnings))\n"
     ]
    }
   ],
   "source": [
    "structure=[]\n",
    "for i in range (1, len(filenames)):\n",
    "    temp= \"cifmegnet/\" +filenames[i]+ \".cif\"\n",
    "    structure.append(Structure.from_file(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model <a class=\"anchor\" id=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riyasheth/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_1/set2set_atom/Reshape_9:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_1/set2set_atom/Reshape_8:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_1/set2set_atom/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/riyasheth/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_1/set2set_bond/Reshape_9:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_1/set2set_bond/Reshape_8:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_1/set2set_bond/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/riyasheth/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_1/set2set_atom/Reshape_27:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_1/set2set_atom/Reshape_26:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_1/set2set_atom/Cast_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/riyasheth/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_1/set2set_bond/Reshape_27:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_1/set2set_bond/Reshape_26:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_1/set2set_bond/Cast_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/riyasheth/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_1/set2set_atom/Reshape_45:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_1/set2set_atom/Reshape_44:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_1/set2set_atom/Cast_4:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/riyasheth/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_1/set2set_bond/Reshape_45:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_1/set2set_bond/Reshape_44:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_1/set2set_bond/Cast_4:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 43s 986ms/step - loss: 0.4063\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 23s 1s/step - loss: 0.2585\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 22s 935ms/step - loss: 0.2515\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 20s 871ms/step - loss: 0.2494\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 20s 873ms/step - loss: 0.2510\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 20s 871ms/step - loss: 0.2489\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 22s 920ms/step - loss: 0.2487\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 20s 870ms/step - loss: 0.2462\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 21s 901ms/step - loss: 0.2465\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 23s 964ms/step - loss: 0.2464\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 20s 873ms/step - loss: 0.2439\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 20s 874ms/step - loss: 0.2430\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 20s 861ms/step - loss: 0.2464\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 20s 876ms/step - loss: 0.2453\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 20s 873ms/step - loss: 0.2452\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 21s 883ms/step - loss: 0.2424\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 20s 898ms/step - loss: 0.2418\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 21s 876ms/step - loss: 0.2427\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 20s 876ms/step - loss: 0.2414\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 21s 879ms/step - loss: 0.2440\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 21s 891ms/step - loss: 0.2436\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 22s 963ms/step - loss: 0.2426\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 23s 995ms/step - loss: 0.2472\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 23s 995ms/step - loss: 0.2456\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 24s 991ms/step - loss: 0.2409\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 23s 983ms/step - loss: 0.2411\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 24s 1s/step - loss: 0.2437\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 23s 1s/step - loss: 0.2411\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 21s 914ms/step - loss: 0.2455\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 22s 966ms/step - loss: 0.2431\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 25s 1s/step - loss: 0.2414\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 22s 973ms/step - loss: 0.2410\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 22s 958ms/step - loss: 0.2426\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 22s 935ms/step - loss: 0.2426\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 21s 933ms/step - loss: 0.2422\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 23s 975ms/step - loss: 0.2425\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 23s 985ms/step - loss: 0.2438\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 22s 961ms/step - loss: 0.2421\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 23s 958ms/step - loss: 0.2415\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 22s 950ms/step - loss: 0.2426\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 23s 1s/step - loss: 0.2412\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 23s 998ms/step - loss: 0.2429\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 31s 1s/step - loss: 0.2416\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.2441\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 23s 992ms/step - loss: 0.2423\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 21s 906ms/step - loss: 0.2469\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 22s 932ms/step - loss: 0.2421\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.2447\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 24s 1s/step - loss: 0.2408\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 23s 997ms/step - loss: 0.2425\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 23s 980ms/step - loss: 0.2417\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 21s 921ms/step - loss: 0.2408\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 21s 895ms/step - loss: 0.2446\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 21s 891ms/step - loss: 0.2429\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 25s 1s/step - loss: 0.2426\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 24s 1s/step - loss: 0.2417\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.2445\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 23s 1s/step - loss: 0.2425\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 23s 989ms/step - loss: 0.2407\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 23s 994ms/step - loss: 0.2436\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 21s 883ms/step - loss: 0.2440\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 20s 855ms/step - loss: 0.2440\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 22s 932ms/step - loss: 0.2430\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 23s 994ms/step - loss: 0.2422\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 20s 851ms/step - loss: 0.2441\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 21s 885ms/step - loss: 0.2422\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 20s 854ms/step - loss: 0.2420\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 20s 854ms/step - loss: 0.2411\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 20s 862ms/step - loss: 0.2444\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 20s 858ms/step - loss: 0.2442\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 20s 862ms/step - loss: 0.2431\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 20s 851ms/step - loss: 0.2451\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 21s 911ms/step - loss: 0.2429\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 24s 1s/step - loss: 0.2409\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 24s 1s/step - loss: 0.2424\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 22s 931ms/step - loss: 0.2416\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 23s 1s/step - loss: 0.2413\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 21s 901ms/step - loss: 0.2417\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 20s 896ms/step - loss: 0.2426\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 20s 841ms/step - loss: 0.2427\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 20s 884ms/step - loss: 0.2425\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 19s 866ms/step - loss: 0.2436\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 20s 877ms/step - loss: 0.2390\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 20s 848ms/step - loss: 0.2419\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 20s 848ms/step - loss: 0.2420\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 21s 906ms/step - loss: 0.2394\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 24s 1s/step - loss: 0.2434\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 22s 956ms/step - loss: 0.2393\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 21s 914ms/step - loss: 0.2397\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 20s 880ms/step - loss: 0.2406\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 20s 856ms/step - loss: 0.2404\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 20s 870ms/step - loss: 0.2377\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 20s 858ms/step - loss: 0.2397\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 20s 860ms/step - loss: 0.2371\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 20s 851ms/step - loss: 0.2396\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 20s 852ms/step - loss: 0.2391\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 20s 854ms/step - loss: 0.2388\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 20s 860ms/step - loss: 0.2350\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 20s 857ms/step - loss: 0.2372\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 20s 855ms/step - loss: 0.2385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<megnet.models.megnet.MEGNetModel at 0x10eba6c40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(structure, propertylist, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Accuracy <a class=\"anchor\" id=\"acc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.5249738037024101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5249738037024101"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_accuracy():\n",
    "    choice= [0, 1]\n",
    "    count=0\n",
    "    for i in range (0, len(structure)):\n",
    "        temp= model.predict_structure(structure[i])\n",
    "        t= temp[0]\n",
    "        result= random.choices(choice, weights= (1-t, t), k=1) \n",
    "        #since this is a probabilistic classification, there should be a randomly weighted choice based on the\n",
    "        #probability predicted by the model\n",
    "        if result[0] == propertylist[i]:\n",
    "            count= count+1\n",
    "            \n",
    "    accuracy= count/len(structure)\n",
    "    print(\"The accuracy is\", accuracy)\n",
    "    return accuracy\n",
    "calculate_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
